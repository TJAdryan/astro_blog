[
  {
    "id": "http://arxiv.org/abs/1501.04832v1",
    "title": "Big Data: How Geo-information Helped Shape the Future of Data Engineering",
    "summary": "Very large data sets are the common rule in automated mapping, GIS, remote sensing, and what we can name geo-information. Indeed, in 1983 Landsat was already delivering gigabytes of data, and other sensors were in orbit or ready for launch, and a tantamount of cartographic data was being digitized. The retrospective paper revisits several issues that geo-information sciences had to face from the early stages on, including: structure ( to bring some structure to the data registered from a sampled signal, metadata); processing (huge amounts of data for big computers and fast algorithms); uncertainty (the kinds of errors, their quantification); consistency (when merging different sources of data is logically allowed, and meaningful); ontologies (clear and agreed shared definitions, if any kind of decision should be based upon them). All these issues are the background of Internet queries, and the underlying technology has been shaped during those years when geo-information engineering emerged.",
    "link": "http://arxiv.org/abs/1501.04832v1",
    "source": "arXiv",
    "topic": "Data Engineering",
    "dateAdded": "2026-01-04T22:23:53.718Z"
  },
  {
    "id": "http://arxiv.org/abs/2507.13892v2",
    "title": "Towards Next Generation Data Engineering Pipelines",
    "summary": "Data engineering pipelines are a widespread way to provide high-quality data for all kinds of data science applications. However, numerous challenges still remain in the composition and operation of such pipelines. Data engineering pipelines do not always deliver high-quality data. By default, they are also not reactive to changes. When new data is coming in which deviates from prior data, the pipeline could crash or output undesired results. We therefore envision three levels of next generation data engineering pipelines: optimized data pipelines, self-aware data pipelines, and self-adapting data pipelines. Pipeline optimization addresses the composition of operators and their parametrization in order to achieve the highest possible data quality. Self-aware data engineering pipelines enable a continuous monitoring of its current state, notifying data engineers on significant changes. Self-adapting data engineering pipelines are then even able to automatically react to those changes. We propose approaches to achieve each of these levels.",
    "link": "http://arxiv.org/abs/2507.13892v2",
    "source": "arXiv",
    "topic": "Data Engineering",
    "dateAdded": "2026-01-19T13:17:03.323Z"
  },
  {
    "id": "37849926",
    "title": "Application of the endogenous CRISPR-Cas type I-D system for genetic engineering in the thermoacidophilic archaeon Sulfolobus acidocaldarius.",
    "summary": "No abstract available via summary API. Please click link to read.",
    "link": "https://pubmed.ncbi.nlm.nih.gov/37849926/",
    "source": "PubMed",
    "topic": "CRISPR",
    "dateAdded": "2026-01-19T13:17:04.230Z"
  },
  {
    "id": "http://arxiv.org/abs/2511.05821v1",
    "title": "PyGress: Tool for Analyzing the Progression of Code Proficiency in Python OSS Projects",
    "summary": "Assessing developer proficiency in open-source software (OSS) projects is essential for understanding project dynamics, especially for expertise. This paper presents PyGress, a web-based tool designed to automatically evaluate and visualize Python code proficiency using pycefr, a Python code proficiency analyzer. By submitting a GitHub repository link, the system extracts commit histories, analyzes source code proficiency across CEFR-aligned levels (A1 to C2), and generates visual summaries of individual and project-wide proficiency. The PyGress tool visualizes per-contributor proficiency distribution and tracks project code proficiency progression over time. PyGress offers an interactive way to explore contributor coding levels in Python OSS repositories. The video demonstration of the PyGress tool can be found at https://youtu.be/hxoeK-ggcWk, and the source code of the tool is publicly available at https://github.com/MUICT-SERU/PyGress.",
    "link": "http://arxiv.org/abs/2511.05821v1",
    "source": "arXiv",
    "topic": "Python",
    "dateAdded": "2026-01-19T13:17:04.456Z"
  },
  {
    "id": "38066376",
    "title": "Genetic Engineering of Therapeutic Phages Using Type III CRISPR-Cas Systems.",
    "summary": "No abstract available via summary API. Please click link to read.",
    "link": "https://pubmed.ncbi.nlm.nih.gov/38066376/",
    "source": "PubMed",
    "topic": "CRISPR",
    "dateAdded": "2026-01-26T13:16:57.194Z"
  },
  {
    "id": "http://arxiv.org/abs/2601.13139v1",
    "title": "From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability",
    "summary": "Refactoring is a software engineering practice that aims to improve code quality without altering program behavior. Although automated refactoring tools have been extensively studied, their practical applicability remains limited. Recent advances in Large Language Models (LLMs) have introduced new opportunities for automated code refactoring. The evaluation of such an LLM-driven approach, however, leaves unanswered questions about its effects on code quality. In this paper, we present a comprehensive empirical study on LLM-driven refactoring using GPT-4o, applied to 100 Python classes from the ClassEval benchmark. Unlike prior work, our study explores a wide range of class-level refactorings inspired by Fowler's catalog and evaluates their effects from three complementary perspectives: (i) behavioral correctness, verified through unit tests; (ii) code quality, assessed via Pylint, Flake8, and SonarCloud; and (iii) readability, measured using a state-of-the-art readability tool. Our findings show that GPT-4o generally produces behavior-preserving refactorings that reduce code smells and improve quality metrics, albeit at the cost of decreased readability. Our results provide new evidence on the capabilities and limitations of LLMs in automated software refactoring, highlighting directions for integrating LLMs into practical refactoring workflows.",
    "link": "http://arxiv.org/abs/2601.13139v1",
    "source": "arXiv",
    "topic": "Python",
    "dateAdded": "2026-01-26T13:16:57.469Z"
  },
  {
    "id": "http://arxiv.org/abs/2504.10950v2",
    "title": "Unveiling Challenges for LLMs in Enterprise Data Engineering",
    "summary": "Large Language Models (LLMs) promise to automate data engineering on tabular data, offering enterprises a valuable opportunity to cut the high costs of manual data handling. But the enterprise domain comes with unique challenges that existing LLM-based approaches for data engineering often overlook, such as large table sizes, more complex tasks, and the need for internal knowledge. To bridge these gaps, we identify key enterprise-specific challenges related to data, tasks, and background knowledge and extensively evaluate how they affect data engineering with LLMs. Our analysis reveals that LLMs face substantial limitations in real-world enterprise scenarios, with accuracy declining sharply. Our findings contribute to a systematic understanding of LLMs for enterprise data engineering to support their adoption in industry.",
    "link": "http://arxiv.org/abs/2504.10950v2",
    "source": "arXiv",
    "topic": "Data Engineering",
    "dateAdded": "2026-02-02T13:24:58.660Z"
  },
  {
    "id": "36842543",
    "title": "CRISPR/Cas advancements for genome editing, diagnosis, therapeutics, and vaccine development for Plasmodium parasites, and genetic engineering of Anopheles mosquito vector.",
    "summary": "No abstract available via summary API. Please click link to read.",
    "link": "https://pubmed.ncbi.nlm.nih.gov/36842543/",
    "source": "PubMed",
    "topic": "CRISPR",
    "dateAdded": "2026-02-02T13:24:59.255Z"
  },
  {
    "id": "http://arxiv.org/abs/2601.01320v1",
    "title": "Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python",
    "summary": "Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.",
    "link": "http://arxiv.org/abs/2601.01320v1",
    "source": "arXiv",
    "topic": "Python",
    "dateAdded": "2026-02-02T13:24:59.532Z"
  },
  {
    "id": "http://arxiv.org/abs/2503.16079v2",
    "title": "Efficient Data Ingestion in Cloud-based architecture: a Data Engineering Design Pattern Proposal",
    "summary": "In today's fast-paced digital world, data has become a critical asset for enterprises across various industries. However, the exponential growth of data presents significant challenges in managing and utilizing the vast amounts of information collected. Data engineering has emerged as a vital discipline addressing these challenges by providing robust platforms for effective data management, processing, and utilization. Data Engineering Patterns (DEP) refer to standardized practices and procedures in data engineering, such as ETL (extract, transform, load) processes, data pipelining, and data streaming management. Data Engineering Design Patterns (DEDP) are best practice solutions to common problems in data engineering, involving established, tested, and optimized approaches. These include architectural decisions, data modeling techniques, and data storage and retrieval strategies. While many researchers and practitioners have identified various DEPs and proposed DEDPs, such as data mesh and lambda architecture, the challenge of high-volume data ingestion remains inadequately addressed. In this paper, we propose a data ingestion design pattern for big data in cloud architecture, incorporating both incremental and full refresh techniques. Our approach leverages a flexible, metadata-driven framework to enhance feasibility and flexibility. This allows for easy changes to the ingestion type, schema modifications, table additions, and the integration of new data sources, all with minimal effort from data engineers. Tested on the Azure cloud architecture, our experiments demonstrate that the proposed techniques significantly reduce data ingestion time. Overall, this paper advances data management practices by presenting a detailed exploration of data ingestion challenges and defining a proposal for an effective design patterns for cloud-based architectures.",
    "link": "http://arxiv.org/abs/2503.16079v2",
    "source": "arXiv",
    "topic": "Data Engineering",
    "dateAdded": "2026-02-09T13:29:09.440Z"
  },
  {
    "id": "40598996",
    "title": "Development of a CRISPR/Cas9 RNP-mediated genetic engineering system in Paecilomyces variotii.",
    "summary": "No abstract available via summary API. Please click link to read.",
    "link": "https://pubmed.ncbi.nlm.nih.gov/40598996/",
    "source": "PubMed",
    "topic": "CRISPR",
    "dateAdded": "2026-02-09T13:29:09.665Z"
  }
]